true_rv=c(40,20,40,20)
true_gv=c(.20,.40,.40,.20)
# Initialize expected values that the simulated subject uses
rv <- c(30,30,30,30)
g<-c(.30,.30,.30,.30)
# loop through each trial and simulate choice
sim_choice <- foreach(t=seq_along(data$Chosen), .combine = "c") %do% {
# Extract reward value of each target (left, right)
rvLeft=rv[data$Left[t]]
rvRight=rv[data$Right[t]]
# Extract generosity of each target (left, right)
gLeft=g[data$Left[t]]
gRight=g[data$Right[t]]
# Convert generosity to an expected point value, using the mean of the point
# distribution (100 poitns)
gvLeft=gLeft*100
gvRight=gRight*100
# Construct overall expected value as weighted average of reward value and
# generosity-based value
evLeft = w*gvLeft+(1-w)*rvLeft
evRight=w*gvRight+(1-w)*rvRight
# Enter into softmax equation, getting probability of choosing the target on
# the left
pr <- softmax(evLeft,evRight,beta)
# Make choice based on softmax probability
r=runif(1)
sim_choice=data$Left[t]*(r<=pr) + data$Right[t]*(r>pr)
# Generate feedback based on simulated choice
sim_reward=round(true_rv[sim_choice]+rnorm(1,mean=0,sd=10))
sim_reward=ifelse(sim_reward < 1, 1, sim_reward)
sim_generosity=true_gv[sim_choice]+rnorm(1,mean=0,sd=.10)
sim_generosity=ifelse(sim_generosity<.01,.01,sim_generosity)
sim_generosity=ifelse(sim_generosity>.99,.99,sim_generosity)
# Update reward and generosity with delta-rule learning
rv[data$Chosen[t]] <- rv[data$Chosen[t]] + alpha * (sim_reward - rv[data$Chosen[t]])
g[data$Chosen[t]] <- g[data$Chosen[t]] + alpha * (sim_generosity - g[data$Chosen[t]])
sim_choice
}
as.numeric(sim_choice)
}
# Simulate the model with parameters fitted when w was free
# Initialize vectors to store the mean of proportions for each iteration
gen_props_means_wFree <- numeric(10)
rew_props_means_wFree <- numeric(10)
# Iterate many times--10 here, but would usually increase to at least 100
for (i in 1:10) {
# Apply the sim_choice function defined above to each subject's data
splits = split(dat, dat$ID)
results = lapply(splits, function(subdat) sim_choice(mean_params, subdat))
dat$sim_choices = unlist(results)
# Compute gen_props and rew_props, as in our first code chunk examining qualitative data patterns--how often subjects chose generous targets and rewarding targets
gen_props <- tapply(dat$sim_choices, dat$ID, function(choices) {
length(which(choices == 2 | choices == 3)) / length(choices)
})
rew_props <- tapply(dat$sim_choices, dat$ID, function(choices) {
length(which(choices == 1 | choices == 3)) / length(choices)
})
# Take the mean of gen_props and rew_props for this iteration
gen_props_means_wFree[i] <- mean(gen_props)
rew_props_means_wFree[i] <- mean(rew_props)
}
# Compute the grand means across all iterations
grand_mean_gen_props_wFree <- mean(gen_props_means_wFree)
grand_mean_rew_props_wFree <- mean(rew_props_means_wFree)
# Now repeat the same procedure while w =0
# Initialize vectors to hold data
gen_props_means_w0 <- numeric(10)
rew_props_means_w0 <- numeric(10)
# Iterate many times--10 here, but would usually increase to at least 100
for (i in 1:10) {
# Apply the sim_choice function to each subset
splits = split(dat, dat$ID)
results = lapply(splits, function(subdat) sim_choice(c(mean_params[1],mean_params[2],0), subdat))
dat$sim_choices_w0 = unlist(results)
# Compute gen_props and rew_props
gen_props_w0 <- tapply(dat$sim_choices_w0, dat$ID, function(choices) {
length(which(choices == 2 | choices == 3)) / length(choices)
})
rew_props_w0 <- tapply(dat$sim_choices_w0, dat$ID, function(choices) {
length(which(choices == 1 | choices == 3)) / length(choices)
})
# Take the mean of gen_props and rew_props for this iteration
gen_props_means_w0[i] <- mean(gen_props_w0)
rew_props_means_w0[i] <- mean(rew_props_w0)
}
# Compute the grand means across all iterations
grand_mean_gen_props_w0 <- mean(gen_props_means_w0)
grand_mean_rew_props_w0 <- mean(rew_props_means_w0)
# Visualize the output
# Put means together in a data frame
sim_means <- data.frame(
Category = c("Chose Generous", "Chose Generous", "Chose Rewarding", "Chose Rewarding"),
Value = c(mean(grand_mean_gen_props_wFree), mean(grand_mean_gen_props_w0),
mean(grand_mean_rew_props_wFree), mean(grand_mean_rew_props_w0)),
Type = c("WFree", "W0", "WFree", "W0")
)
# Add data to previous plot of qualitative patterns in actual choice behavior
ggplot() +
geom_bar(data = data_means, aes(x = Category, y = Value), stat = "identity", width = 0.4,fill="lightblue") +
geom_point(data = sim_means, aes(x = Category, y = Value, color = Type), size = 3) +
geom_hline(yintercept = .5,linetype='dotted',)+
theme_minimal() +
labs(x = "Category", y = "Value", title = "Bar Plot of Means with Overlay Points") +
scale_fill_brewer(palette = "Set1") +
scale_color_manual(values = c("WFree" = "blue", "W0" = "red"))
# Create a function just like the simulation above, but outputting the total number of points a simulated subject earned in the task
sim_reward <- function(par, data)  {
# Extract parameters from input vector
alpha=par[1]
beta=par[2]
w=par[3]
# Set true feedback values used to give feedback to simulated subject
true_rv=c(40,20,40,20)
true_gv=c(.20,.40,.40,.20)
# Initialize expected value for each target
rv <- c(30,30,30,30)
g<-c(.30,.30,.30,.30)
# Loop through each trial and simulate choice
sim_reward <- foreach(t=seq_along(data$Chosen), .combine = "c") %do% {
# Extract reward value of each target (left, right)
rvLeft=rv[data$Left[t]]
rvRight=rv[data$Right[t]]
# Extract generosity of each target (left, right)
gLeft=g[data$Left[t]]
gRight=g[data$Right[t]]
# Convert generosity to an expected point value, using the mean of the point
# distribution (100 poitns)
gvLeft=gLeft*100
gvRight=gRight*100
# Construct overall expected value as weighted average of reward value and
# generosity-based value
evLeft = w*gvLeft+(1-w)*rvLeft
evRight=w*gvRight+(1-w)*rvRight
# Enter to softmax equation, getting probability of choosing the target on
# the left
pr <- softmax(evLeft,evRight,beta)
# Make choice
r=runif(1)
sim_choice=data$Left[t]*(r<=pr) + data$Right[t]*(r>pr)
# Generate reward based on simulated choice
sim_reward=round(true_rv[sim_choice]+rnorm(1,mean=0,sd=10))
sim_reward=ifelse(sim_reward < 1, 1, sim_reward)
sim_generosity=true_gv[sim_choice]+rnorm(1,mean=0,sd=.10)
sim_generosity=ifelse(sim_generosity<.01,.01,sim_generosity)
sim_generosity=ifelse(sim_generosity>.99,.99,sim_generosity)
# Update reward and generosity with delta-rule learning
rv[data$Chosen[t]] <- rv[data$Chosen[t]] + alpha * (sim_reward - rv[data$Chosen[t]])
g[data$Chosen[t]] <- g[data$Chosen[t]] + alpha * (sim_generosity - g[data$Chosen[t]])
sim_reward
}
as.numeric(sim_reward)
}
# Initialize vector for output
reward_sums=numeric(3)
# Apply this reward simulation function to each subset if w = 0
results_w0 = lapply(splits, function(subdat) sim_reward(c(mean_params[1],mean_params[2],
0), subdat))
reward_sums[1] <- mean(tapply(unlist(results_w0), dat$ID, sum)) # Average rewards across subjects
# Apply reward simulation if w = .5 (equal weighting of reward and generosity)
results_wEqual = lapply(splits, function(subdat) sim_reward(c(mean_params[1],mean_params[2],
.5), subdat))
reward_sums[2] <- mean(tapply(unlist(results_wEqual), dat$ID, sum))
# Apply reward simulation if w = 1
results_w1 = lapply(splits, function(subdat) sim_reward(c(mean_params[1],mean_params[2],
1), subdat))
reward_sums[3] <- mean(tapply(unlist(results_w1), dat$ID, sum))
names(reward_sums)=c("W_0","W_0.5","W_1")
reward_sums
library(ggplot2)
packageVersion("ggplot2")
summary(glm4)
View(data)
install.packages("pwr2")
library(pwr2)
# Example parameters
p0 <- 0.1  # Baseline probability of event
OR <- 1.5  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
k <- 1  # Number of predictors
# Conduct power analysis
result <- SSizeLogisticBin(p1=p0, p2=OR*p0/(1-p0*(1-OR)), alpha=alpha, power=power, r2=0, k=k)
install.packages("pwr2")
library(pwr2)
install.packages("pwr2")
p0 <- 0.1  # Baseline probability of event
OR <- 1.5  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
k <- 1  # Number of predictors
result <- SSizeLogisticBin(p1=p0, p2=OR*p0/(1-p0*(1-OR)), alpha=alpha, power=power, r2=0, k=k)
install.packages("Hmisc")
library(Hmisc)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- 1.5  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
# Calculate the probability for the alternative hypothesis
p1 <- OR * p0 / (1 - p0 + OR * p0)
# Calculate the sample size
result <- bsamsize(p0, p1, fraction=0.5, alpha=alpha, power=power)
# Output the result
print(result)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- .75  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
> # Calculate the sample size
library(Hmisc)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- .7  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
# Calculate the probability for the alternative hypothesis
p1 <- OR * p0 / (1 - p0 + OR * p0)
# Calculate the sample size
result <- bsamsize(p0, p1, fraction=0.5, alpha=alpha, power=power)
# Output the result
print(result)
library(Hmisc)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- 2.0  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
# Calculate the probability for the alternative hypothesis
p1 <- OR * p0 / (1 - p0 + OR * p0)
# Calculate the sample size
result <- bsamsize(p0, p1, fraction=0.5, alpha=alpha, power=power)
# Output the result
print(result)
library(Hmisc)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- -2.0  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
# Calculate the probability for the alternative hypothesis
p1 <- OR * p0 / (1 - p0 + OR * p0)
# Calculate the sample size
result <- bsamsize(p0, p1, fraction=0.5, alpha=alpha, power=power)
# Output the result
print(result)
library(Hmisc)
# Example parameters
p0 <- 0.1  # Baseline probability of the event
OR <- 1.47  # Expected odds ratio
alpha <- 0.05  # Significance level
power <- 0.80  # Desired power
# Calculate the probability for the alternative hypothesis
p1 <- OR * p0 / (1 - p0 + OR * p0)
# Calculate the sample size
result <- bsamsize(p0, p1, fraction=0.5, alpha=alpha, power=power)
# Output the result
print(result)
summary(glm2)
summary(gml1)
summary(glm1)
summary(glm3)
summary(glm4)
plot_model(model=glm3)
library(lme4)
library(lmerTest)
plot_model(model=glm3)
library(ggplot2)
plot_model(glm3, type="pred")
install.packages("sjPlot")
install.packages("sjmisc")
install.packages("ggplot2")
library(sjPlot)
library(sjmisc)
library(ggplot2)
install.packages("ggplot2")
plot_model(glm3, type=c("pred"), axis.title =c("Social Condition", "Predicted Probability of Playing Lottery"),title='',colors=("circus"),mrdt.values="meansd"))
plot_model(glm3, type=c("pred"), axis.title =c("Social Condition", "Predicted Probability of Playing Lottery"),title='',colors=("circus"),mrdt.values="meansd")
library(sjPlot)
plot(glm3)
summary(glm3)
plot_model(glm3,type=c("pred"),axis.title = c('Social Condition','Predicted Probability of Playing Lottery'),title='',colors=("circus"),mrdt.values="meansd")
plot(data$condition_recode, data$playlottery, xlab = "Social Condition", ylab = "Self-Choice", main = "GLM Predictions", pch = 16, col = 'blue')
# Create a data frame for unique levels of condition_recode
pred_data <- data.frame(condition_recode = levels(data$condition_recode))
# Predict the response
pred_data$predicted_prob <- predict(glm_model, newdata = pred_data, type = "response")
# Create a data frame for unique levels of condition_recode
pred_data <- data.frame(condition_recode = levels(data$condition_recode))
# Predict the response
pred_data$predicted_prob <- predict(glm3, newdata = pred_data, type = "response")
# Create a data frame for unique levels of condition_recode
pred_data <- data(condition_recode = levels(data$condition_recode))
# Predict the response
pred_data$predicted_prob <- predict(glm3, newdata = pred_data, type = "response")
View(data)
View(predicted_probs)
view(predicted_probs_glm5)
View(predicted_probs_glm5)
# Create a data frame for unique levels of condition_recode
pred_data <- data.frame(condition_recode = unique(data$condition_recode))
# Predict the response probabilities
pred_data$predicted_prob <- predict(glm3, newdata = pred_data, type = "response")
# Create a data frame for unique levels of condition_recode
pred_data <- data.frame(condition_recode = unique(data$condition_recode))
# Predict the response probabilities
pred_data$condition_recode <- factor(pred_data$condition_recode, levels = levels(data$condition_recode))
ggplot(data, aes(x=condition_recode, y=playlottery)) + geom_point() +
stat_smooth(method="glm", color="green", se=FALSE,
method.args = list(family=binomial))
install(ggplot)
install.packages("ggplot")
library(ggplot2)
ggplot(data, aes(x=condition_recode, y=playlottery)) + geom_point() +
stat_smooth(method="glm", color="green", se=FALSE,
method.args = list(family=binomial))
View(data)
ggplot(data2, aes(x=condition_recode, y=playlottery)) + geom_point() +
stat_smooth(method="glm", color="green", se=FALSE,
method.args = list(family=binomial))
ggplot(data2_clean, aes(x = condition_recode, y = playlottery)) +
geom_point() +
stat_smooth(method = "glm", color = "green", se = FALSE,
method.args = list(family = binomial)) +
labs(x = "Condition Recode", y = "Play Lottery", title = "Logistic Regression with ggplot2") +
theme_minimal()
ggplot(data3, aes(x = condition_recode, y = playlottery)) +
geom_point() +
stat_smooth(method = "glm", color = "green", se = FALSE,
method.args = list(family = binomial)) +
labs(x = "Condition Recode", y = "Play Lottery", title = "Logistic Regression with ggplot2") +
theme_minimal()
View(data)
View(data)
View(data)
rm(data)
rm(bms0)
rm(best_opt)
rm(bms_matrix)
rm(bms_mat)
rm(dat)
rm(data_means)
rm(data_points)
rm(w)
rm(t)
rm(rvLeft)
rm(rvRight)
rm(rv)
rm(reward_sums)
rm(reward_props)
rm(reward_props_w0)
rm(rew_props_w0)
rm(rew_props_means_w0)
rm(rew_props_means_wFree)
rm(rew_props)
rm(softmax)
rm(slm_reward)
rm(slm_reward)
View(sim_reward)
rm(sim_reward)
rm(sim_choice)
rm(map_trait)
rm(get_regressors)
rm(residuals)
rm(prChoice)
rm(pr)
rm(params)
rm(out)
rm(num_iter)
rm(num_param)
rm(med_params)
rm(mean_params)
rm(gRight)
rm(gvRight)
rm(gvLeft)
rm(grand_mean_gen_props_w0)
rm(grand_mean_gen_props_wFree)
rm(grand_mean_rew_props_w0)
rm(grand_mean_rew_props_wFree)
rm(i)
rm(g)
rm(evLeft)
rm(evRight)
rm(gen_props)
rm(gen_props_means_w0)
rm(gen_props_means_wFree)
rm(gen_props_w0)
rm(gleft)
rm(gLeft)
rm(alpha)
rm(beta)
rm(splits)
rm(sim_means)
rm(results_w0)
rm(results_w1)
rm(results_wEqual)
View(starting_values)
rm(starting_values)
rm(outputs)
rm(subject_output)
rm(opt)
rm(pred_data)
rm(est)
rm(all_fits_w0)
rm(all_fits_wFree)
save.image("~/Documents/GitHub/Rejection_Choice/workspace.RData")
library(lme4)
library(lme4)
library(lmerTest)
library(Rcpp)
library(Matrix)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(tidyr)
library(effsize)
setwd("/Users/jordansiegel/Documents/Github/WTP_Rejection_Choice/scoring")
rsq <- read.csv(file="rsq.csv", header =TRUE, sep = ',')
setwd("/Users/jordansiegel/Documents/Github/WTP_Rejection_Choice/")
wtp_rej_longdata<-read.csv(file="longformdata.csv",header=TRUE, sep=',')
wtp_rej_shortdata<-read.csv(file="shortformdata.csv",header=TRUE, sep=',')
#re-code acceptance from 2 to -1 for condition_recode and males from 0 to -1 in sex
wtp_rej_longdata$condition_recode[wtp_rej_longdata$condition_recode==2]<- -1
wtp_rej_longdata$sex[wtp_rej_longdata$sex==0]<- -1
#re-code acceptance from 2 to -1 for condition_recode and males from 0 to -1 in sex
wtp_rej_shortdata$condition_recode[wtp_rej_shortdata$condition_recode==2]<- -1
wtp_rej_shortdata$sex[wtp_rej_shortdata$sex==0]<- -1
# Create prop_nonsocialchoice as the absolute difference from 1
wtp_rej_shortdata <- wtp_rej_shortdata %>%
mutate(prop_nonsocialchoice = abs(prop_socialchoice - 1))
wtp_rej_longdata <- wtp_rej_longdata %>%
mutate(prop_nonsocialchoice = abs(prop_socialchoice - 1))
# Check if the column was created correctly
head(wtp_rej_shortdata)
#create seperate variables with values for within each condition
# Subset data where condition_recode == 1
rej <- wtp_rej_shortdata %>%
filter(condition_recode == 1) %>%
as.data.frame()  # Ensure it's a data frame if needed
# Subset data where condition_recode == 2
acc <- wtp_rej_shortdata %>%
filter(condition_recode == -1) %>%
as.data.frame()
# Subset data where condition_recode == 1
rej_long <- wtp_rej_longdata %>%
filter(condition_recode == 1) %>%
as.data.frame()  # Ensure it's a data frame if needed
# Subset data where condition_recode == 2
acc_long <- wtp_rej_longdata %>%
filter(condition_recode == -1) %>%
as.data.frame()
pca_data<-read.csv(file='wtp_rej_PCA_allsubjects.csv',header=TRUE, sep=',')
setwd("/Users/jordansiegel/Documents/Github/WTP_Rejection_Choice/scoring")
pca_data<-read.csv(file='wtp_rej_PCA_allsubjects.csv',header=TRUE, sep=',')
condition_choiceprice_withpca <- lmer(decision_price ~ condition_recode + age + order_var + sex + timebetween +
PC1 + PC2 + PC3 + (1 | participant),
data = wtp_rej_longdata)
colnames(wtp_rej_longdata)[colnames(wtp_rej_longdata) == "order"] <- "order_var"
condition_choiceprice_withpca <- lmer(decision_price ~ condition_recode + age + order_var + sex + timebetween +
PC1 + PC2 + PC3 + (1 | participant),
data = wtp_rej_longdata)
# Merge PCA components into your main dataset
merged_data <- merge(wtp_rej_longdata, pca_scores, by = "participant")
colnames(wtp_rej_longdata)
colnames(pca_df)
colnames(wtp_rej_longdata)
colnames(pca_data)
# Merge PCA components into your main dataset
merged_data <- merge(wtp_rej_longdata, pca_scores, by = "participant")
# Merge PCA components into your main dataset
merged_data <- merge(wtp_rej_longdata, pca_data, by = "participant")
# Merge PCA components into your main dataset
merged_data <- left_join(wtp_rej_longdata, pca_df, by = "participant")
merged_data <- left_join(wtp_rej_longdata, pca_data, by = "participant")
colnames(pca_data)[colnames(pca_data) == "Prolific_ID"] <- "participant"
merged_data <- left_join(wtp_rej_longdata, pca_data, by = "participant")
condition_choiceprice_withpca <- lmer(decision_price ~ condition_recode + age + order_var + sex + timebetween +
PC1 + PC2 + PC3 + (1 | participant),
data = wtp_rej_longdata)
condition_choiceprice_withpca <- lmer(decision_price ~ condition_recode + age + order_var + sex + timebetween +
PC1 + PC2 + PC3 + (1 | participant),
data = merged_data)
summary(condition_choiceprice_withpca)
+                                       data = merged_data)
condition_choicetype_withpca <- lmer(socialchoice ~ condition_recode + age + order_var + sex + timebetween + PC1 + PC2 + PC3 + (1 | participant),data = merged_data)
summary(condition_choicetype_withpca)
model_interaction <- lmer(decision_price ~ condition_recode * (PC1 + PC2 + PC3) +
age + order_var + sex + timebetween + (1 | participant),
data = merged_data)
summary(model_interaction)
model_interaction_choicetype <- lmer(socialchoice ~ condition_recode * (PC1 + PC2 + PC3) +
age + order_var + sex + timebetween + (1 | participant),
data = merged_data)
summary(model_interaction_choicetype)
merged_data_rej <- subset(merged_data, condition_recode == "1")
merged_data_acc <- subset(merged_data, condition_recode == "-1")
###running by models within conditions
merged_data_rej <- subset(merged_data, condition_recode == "1")
merged_data_acc <- subset(merged_data, condition_recode == "-1")
model_rej <- lmer(decision_price ~ PC1 + PC2 + PC3 + age + order_var + sex + timebetween + (1 | participant),
data = merged_data_rej)
model_acc <- lmer(decision_price ~ PC1 + PC2 + PC3 + age + order_var + sex + timebetween + (1 | participant),
data = merged_data_acc)
summary(model_rej)
summary(model_acc)
condition_choiceprice_withpcaonly <- lmer(decision_price ~ condition_recode + PC1 + PC2 + PC3 + (1 | participant), data = merged_data)
summary(condition_choiceprice_withpcaonly)
condition_choiceprice_withpcaonly <- lmer(decision_price ~ condition_recode + PC1 + PC2 + PC3 + (1 | participant), data = merged_data)
condition_choicetype_withpcaonly <- lmer(socialchoice ~ condition_recode + PC1 + PC2 + PC3 + (1 | participant), data = merged_data)
summary(condition_choicetype_withpcaonly)
View(merged_data_acc)
View(merged_data_acc)
